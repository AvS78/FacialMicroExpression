{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import imageio\n",
    "from scipy import sqrt, pi, arctan2, cos, sin # used for HoF\n",
    "from scipy.ndimage import uniform_filter # used for hoF\n",
    "import time\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as skm\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint,CSVLogger,LearningRateScheduler \n",
    "from keras.utils import np_utils, generic_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from keras import backend as K\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "import re\n",
    "import collections\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2plt(img):\n",
    "    plt.axis('off')\n",
    "    if np.size(img.shape) == 3:\n",
    "        plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))#convert first BGR (cv2 format)to matplotlib format (RGB)\n",
    "    else:\n",
    "        plt.imshow(img,cmap='gray',vmin=0,vmax=255)\n",
    "        print(\"NOWHERE\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17248002527952040147\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6630704415\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15418498957484888101\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "\n",
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame loc, frame folder, frame name, frame label C:\\Users\\ajayv\\Desktop\\Db-project2\\CASME-II\\CASME2_RAW_selected\\CASME2_RAW_selected\\sub01\\EP02_01f 1 EP02_01f happiness\n"
     ]
    }
   ],
   "source": [
    "# casmeII RAW selected video frames location\n",
    "data_loc=r\"C:\\Users\\ajayv\\Desktop\\Db-project2\\CASME-II\\CASME2_RAW_selected\\CASME2_RAW_selected\" # r -> raw string reproduce\n",
    "\n",
    "# casmeII video frame label location\n",
    "label_file_path = r'C:\\Users\\ajayv\\Desktop\\Db-project2\\CASME-II'\n",
    "\n",
    "#### extracting the frame name from the location... alternate to building frame_name_list\n",
    "\n",
    "def extract_subjectnumber(string):\n",
    "\n",
    "# extract the file name from \n",
    "    a = string\n",
    "    b= string[:-2]\n",
    "    if b in a:\n",
    "        c= a.replace(b,'')\n",
    "    return int(c)\n",
    "\n",
    "\n",
    "def extract_label(sub_num,frame_name):\n",
    "    #sub num -> is sub folder number in integer.\n",
    "    #sub num+frame_name represent a unique key in the label file to identify the label\n",
    "    tobematched = str(sub_num)+frame_name\n",
    "    for a in df_label_file.index:\n",
    "        if df_label_file[\"sub-file\"].iloc[a] == tobematched:\n",
    "\n",
    "            label = df_label_file[\"Estimated Emotion\"].iloc[a]\n",
    "\n",
    "            break\n",
    "    return label\n",
    "\n",
    "\n",
    "df_label_file = pd.read_excel(os.path.join(label_file_path, 'CASME2-coding-20190701.xlsx'))\n",
    "\n",
    "\n",
    "df_label_file[\"sub-file\"] = (df_label_file[\"Subject\"]).astype(str) + df_label_file[\"Filename\"].astype(str) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#subject folders (same subject multiple emotion sequences)        \n",
    "folder_list = os.listdir(data_loc)\n",
    "\n",
    "frame_location_list=[] #frame absolute location list\n",
    "frame_folder_list=[] #frame subject folder number \n",
    "frame_name_list=[] #frame name (same name may exist in more then one sub folder)\n",
    "frame_label=[]#frame's label for a given absolute location\n",
    "\n",
    "for a in folder_list:\n",
    "    file_folder_loc = os.path.join(data_loc, a)\n",
    "\n",
    "    files_in_folder = os.listdir(file_folder_loc)\n",
    "\n",
    "    for b in files_in_folder:\n",
    "        \n",
    "        file_loc = os.path.join(file_folder_loc,b)\n",
    "        frame_location_list.append(file_loc) \n",
    "        \n",
    "        sub_num = extract_subjectnumber(a)\n",
    "        frame_folder_list.append(sub_num)\n",
    "        label = extract_label(sub_num,b)\n",
    "        frame_label.append(label)\n",
    "\n",
    "    \n",
    "        frame_name_list.append(b) #save file names for building the labels later with lookup at CASME2-coding-20190701.xlsx\n",
    "\n",
    "\n",
    "        frame_location_list[0], #sequence absolute locations\n",
    "        frame_folder_list[0], #subject folder name\n",
    "        frame_name_list[0], #sequence folder name (same sequence name may exist at different subjects)\n",
    "        frame_label[0] ) #sequence label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DLib Face Detection\n",
    "# predictor_path = \"shape_predictor_68_face_landmarks.dat\"\n",
    "predictor_path=r\"C:\\Users\\ajayv\\iCloudDrive\\Documents\\01-knowledge\\01-NUS-MTechISS\\01-2020sem1\\project2\\code\\shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmark(img):\n",
    "    \n",
    "   # cv2plt(img)\n",
    "    rects = detector(img, 1)\n",
    "  #  print(rects[0])\n",
    "    if len(rects) > 1:\n",
    "        pass\n",
    "    if len(rects) == 0:\n",
    "        pass\n",
    "    ans = np.matrix([[p.x, p.y] for p in predictor(img, rects[0]).parts()])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#to sort images: temporal sequence frame processing\n",
    "numbers=re.compile(r'(\\d+)')\n",
    "def numericalsort(value):\n",
    "    parts=numbers.split(value)\n",
    "    parts[1::2]=map(int, parts[1::2])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://github.com/colincsl/pyKinectTools/blob/master/pyKinectTools/algs/HistogramOfOpticalFlow.py\n",
    "\n",
    "def hof(flow, orientations=9, pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(2, 2), normalise=False, motion_threshold=1.):\n",
    "\n",
    "    flow = np.atleast_2d(flow)\n",
    "\n",
    "    if flow.ndim < 3:\n",
    "        raise ValueError(\"Requires dense flow in both directions\")\n",
    "\n",
    "    if normalise:\n",
    "        flow = sqrt(flow)\n",
    "\n",
    "\n",
    "    if flow.dtype.kind == 'u':\n",
    "        # convert uint image to float\n",
    "        # to avoid problems with subtracting unsigned numbers in np.diff()\n",
    "        flow = flow.astype('float')\n",
    "\n",
    "    gx = np.zeros(flow.shape[:2])\n",
    "    gy = np.zeros(flow.shape[:2])\n",
    "    # gx[:, :-1] = np.diff(flow[:,:,1], n=1, axis=1)\n",
    "    # gy[:-1, :] = np.diff(flow[:,:,0], n=1, axis=0)\n",
    "\n",
    "    gx = flow[:,:,1]\n",
    "    gy = flow[:,:,0]\n",
    "\n",
    "    magnitude = sqrt(gx**2 + gy**2)\n",
    "    orientation = arctan2(gy, gx) * (180 / pi) % 180\n",
    "\n",
    "    sy, sx = flow.shape[:2]\n",
    "    cx, cy = pixels_per_cell\n",
    "    bx, by = cells_per_block\n",
    "\n",
    "    n_cellsx = int(np.floor(sx // cx))  # number of cells in x\n",
    "    n_cellsy = int(np.floor(sy // cy))  # number of cells in y\n",
    "\n",
    "    # compute orientations integral images\n",
    "    orientation_histogram = np.zeros((n_cellsy, n_cellsx, orientations))\n",
    "    subsample = np.index_exp[int(cy / 2):cy * n_cellsy:cy, int(cx / 2):cx * n_cellsx:cx]\n",
    "    for i in range(orientations-1):\n",
    "        #create new integral image for this orientation\n",
    "        # isolate orientations in this range\n",
    "\n",
    "        temp_ori = np.where(orientation < 180 / orientations * (i + 1),\n",
    "                            orientation, -1)\n",
    "        temp_ori = np.where(orientation >= 180 / orientations * i,\n",
    "                            temp_ori, -1)\n",
    "        # select magnitudes for those orientations\n",
    "        cond2 = (temp_ori > -1) * (magnitude > motion_threshold)\n",
    "        temp_mag = np.where(cond2, magnitude, 0)\n",
    "\n",
    "        temp_filt = uniform_filter(temp_mag, size=(cy, cx))\n",
    "        orientation_histogram[:, :, i] = temp_filt[subsample]\n",
    "\n",
    "\n",
    "    temp_mag = np.where(magnitude <= motion_threshold, magnitude, 0)\n",
    "\n",
    "    temp_filt = uniform_filter(temp_mag, size=(cy, cx))\n",
    "    orientation_histogram[:, :, -1] = temp_filt[subsample]\n",
    "\n",
    "\n",
    "    n_blocksx = (n_cellsx - bx) + 1\n",
    "    n_blocksy = (n_cellsy - by) + 1\n",
    "    normalised_blocks = np.zeros((n_blocksy, n_blocksx,\n",
    "                                  by, bx, orientations))\n",
    "\n",
    "    for x in range(n_blocksx):\n",
    "        for y in range(n_blocksy):\n",
    "            block = orientation_histogram[y:y+by, x:x+bx, :]\n",
    "            eps = 1e-5\n",
    "            normalised_blocks[y, x, :] = block / sqrt(block.sum()**2 + eps)\n",
    "\n",
    "    return normalised_blocks.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract Histogram of Optical Flow features for a given consequetive frames. Replace frame by extracted HOG\n",
    "def extract_hof_feature(seq_location_list,seq_label):\n",
    "    feature_hof = []\n",
    "    label_list = []\n",
    "    img_width = 128\n",
    "    img_height = 64\n",
    "    \n",
    "    print(\"total number of sequences are:\", len(seq_location_list))\n",
    "    \n",
    "    #each pass processes a sequence of frame in \n",
    "    for a in range(0,len(seq_location_list)): #idx is to display progress, a is to iterate through CASMEII/SMIC db\n",
    "       # Display the progress\n",
    "        if ((a % 10) == 0):\n",
    "            print(\"process sequence %d /%d\" % (a, len(seq_location_list)))\n",
    "        \n",
    "        hof_feature_all = []\n",
    "\n",
    "        \n",
    "        filepath = seq_location_list[a]\n",
    "        \n",
    "        seq_folder = os.listdir(filepath) # contains the frames for that micro-expression sequence\n",
    "        \n",
    "        #double check: sort the folder to get temporal seq \n",
    "        sort_seq_folder = sorted(seq_folder, key=numericalsort)\n",
    "        \n",
    "        label = seq_label[a]\n",
    "        \n",
    "        \n",
    "        #iterate the frames inside a given sequence\n",
    "        for b in range(0,len(sort_seq_folder)-1):\n",
    "            framepath = os.path.join(filepath, sort_seq_folder[b])\n",
    "            \n",
    "            if (cv2.imread(framepath) is not None):\n",
    "                frame = cv2.imread(framepath)\n",
    "            \n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            previousGray = gray\n",
    "            \n",
    "            framepath_next = os.path.join(filepath, sort_seq_folder[b+1])\n",
    "            \n",
    "            frame_next = cv2.imread(framepath_next)\n",
    "            \n",
    "            gray = cv2.cvtColor(frame_next, cv2.COLOR_BGR2GRAY)\n",
    "            flow = cv2.calcOpticalFlowFarneback(previousGray, gray, \n",
    "                                                flow=None, pyr_scale=0.5, levels=5, winsize=11, \n",
    "                                                iterations=10, poly_n=5, poly_sigma=1.1, flags=0)\n",
    "            \n",
    "            hof_feature_one = hof(flow, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2))\n",
    "            \n",
    "            if (len(hof_feature_all) == 0):\n",
    "                hof_feature_all = hof_feature_one\n",
    "            else:\n",
    "                hof_feature_all = np.vstack((hof_feature_all, hof_feature_one))\n",
    "        \n",
    "                \n",
    "        if (len(hof_feature_all) != 0):\n",
    "            hof_feature_mean = np.mean(hof_feature_all, axis=0)\n",
    "            feature_hof.append(hof_feature_mean)\n",
    "            label_list.append(label)      \n",
    "\n",
    "    return np.array(feature_hof), np.array(label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eye_mouth_img(image):\n",
    "    \n",
    "    landmarks = get_landmark(image)\n",
    "    numpylandmarks = np.asarray(landmarks)\n",
    "    eye_image = image[numpylandmarks[19][1]:numpylandmarks[1][1], numpylandmarks[1][0]:numpylandmarks[15][0]]\n",
    "    eye_image = cv2.resize(eye_image, (32, 32), interpolation = cv2.INTER_AREA)\n",
    "    eye_image = cv2.cvtColor(eye_image, cv2.COLOR_BGR2GRAY)\n",
    "    nose_mouth_image = image[numpylandmarks[2][1]:numpylandmarks[6][1], numpylandmarks[2][0]:numpylandmarks[14][0]]\n",
    "    nose_mouth_image = cv2.resize(nose_mouth_image, (32, 32), interpolation = cv2.INTER_AREA)\n",
    "    nose_mouth_image = cv2.cvtColor(nose_mouth_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    return eye_image, nose_mouth_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract Histogram of Optical Flow features for eye mouth for a given consequetive frames. Replace frame by extracted HOG\n",
    "def extract_hof_eye_mouth_feature(seq_location_list,seq_label):\n",
    "    feature_hof = []\n",
    "    label_list = []\n",
    "    img_width = 128\n",
    "    img_height = 64\n",
    "    \n",
    "    print(\"total number of sequences are:\", len(seq_location_list))\n",
    "    \n",
    "    #each pass processes a sequence of frame in \n",
    "    for a in range(0,len(seq_location_list)): #idx is to display progress, a is to iterate through CASMEII/SMIC db\n",
    "       # Display the progress\n",
    "    \n",
    "    \n",
    "        print(\"folder time\", time.time())\n",
    "        \n",
    "        if ((a % 10) == 0):\n",
    "            print(\"process sequence %d /%d\" % (a, len(seq_location_list)))\n",
    "        \n",
    "        hof_eye_feature_all = [] # eye features\n",
    "        hof_nose_mouth_feature_all = [] # eye features\n",
    "\n",
    "        \n",
    "        filepath = seq_location_list[a]\n",
    "        label = seq_label[a]\n",
    "        \n",
    "        seq_folder = os.listdir(filepath) # contains the frames for that micro-expression sequence\n",
    "        sort_seq_folder = sorted(seq_folder, key=numericalsort)\n",
    "        \n",
    "        for b in range(0,len(sort_seq_folder)-1):\n",
    "            framepath = os.path.join(filepath, sort_seq_folder[b])\n",
    "            \n",
    "            \n",
    "\n",
    "            if (cv2.imread(framepath) is not None):\n",
    "                frame = cv2.imread(framepath)\n",
    "            \n",
    "            framepath_next = os.path.join(filepath, sort_seq_folder[b+1])\n",
    "            \n",
    "            frame_next = cv2.imread(framepath_next)\n",
    "            \n",
    "            \n",
    "            previous_eye, previous_nose_mouth = get_eye_mouth_img(frame)\n",
    "            \n",
    "            eye, nose_mouth = get_eye_mouth_img(frame_next)\n",
    "            \n",
    "            \n",
    "            flow_eye = cv2.calcOpticalFlowFarneback(previous_eye, eye, \n",
    "                                                flow=None, pyr_scale=0.5, levels=5, winsize=11, \n",
    "                                                iterations=10, poly_n=5, poly_sigma=1.1, flags=0)\n",
    "        \n",
    "            flow_nose_mouth = cv2.calcOpticalFlowFarneback(previous_nose_mouth, nose_mouth, \n",
    "                                                flow=None, pyr_scale=0.5, levels=5, winsize=11, \n",
    "                                                iterations=10, poly_n=5, poly_sigma=1.1, flags=0)\n",
    "        \n",
    "            \n",
    "            hof_eye_feature_one = hof(flow_eye, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2))\n",
    "            hof_nose_mouth_feature_one = hof(flow_nose_mouth, orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2))\n",
    "            \n",
    "            if (len(hof_eye_feature_all) == 0):\n",
    "                hof_eye_feature_all = hof_eye_feature_one\n",
    "                hof_nose_mouth_feature_all = hof_nose_mouth_feature_one\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                hof_eye_feature_all = np.vstack((hof_eye_feature_all, hof_eye_feature_one))\n",
    "                hof_nose_mouth_feature_all = np.vstack((hof_nose_mouth_feature_all, hof_nose_mouth_feature_one))\n",
    "        \n",
    "                \n",
    "        if (len(hof_eye_feature_all) != 0):\n",
    "            hof_eye_feature_mean = np.mean(hof_eye_feature_all, axis=0)\n",
    "            hof_nose_mouth_feature_mean = np.mean(hof_nose_mouth_feature_all, axis=0)\n",
    "            feature_hof.append(np.vstack((hof_eye_feature_mean,hof_nose_mouth_feature_mean)))\n",
    "            label_list.append(label)      \n",
    "\n",
    "    return np.array(feature_hof), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_set(features,labels):\n",
    "    \n",
    "    test_samples = []\n",
    "    \n",
    "    train_features = []\n",
    "    test_features = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "    \n",
    "    num_samples = len(features)\n",
    "    \n",
    "    num_test = int(0.2*num_samples)\n",
    "    \n",
    "    random.seed(0)\n",
    "    \n",
    "    test_list_index = random.sample(range(0, num_samples-1), num_test)\n",
    "    \n",
    "    print(test_list_index)\n",
    "    \n",
    "    for a in test_list_index:\n",
    "        test_labels.append(labels[a])\n",
    "        test_features.append(features[a])\n",
    "        \n",
    "    train_features = [i for j, i in enumerate(features) if j not in test_list_index]\n",
    "    train_labels = [i for j, i in enumerate(labels) if j not in test_list_index]\n",
    "    \n",
    "    return np.array(train_features), np.array(train_labels), np.array(test_features), np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#extract features at face\n",
    "\n",
    "now = time.time()\n",
    "\n",
    "feature_hof, label_hof = extract_hof_feature(frame_location_list,frame_label)      \n",
    "\n",
    "print(\"total extraction time\", time.time()-now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('.\\hof_feature_eye_nose, feature_hof',flatt_feature_hof)\n",
    "np.save('.\\label_hof_eye_nose, feature_hof',label_hof)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
